# ğŸ‰ AIThink Ä‘Ã£ Ä‘Æ°á»£c triá»ƒn khai thÃ nh cÃ´ng!

## âœ… Nhá»¯ng gÃ¬ Ä‘Ã£ hoÃ n thÃ nh

### 1. **Backend** (Node.js + Express + Socket.IO)
- âœ… Ollama Service - Káº¿t ná»‘i vá»›i Deepseek-R1:8b
- âœ… Queue Service - Quáº£n lÃ½ táº£i há»‡ thá»‘ng (max 3 requests Ä‘á»“ng thá»i)
- âœ… WebSocket API - Streaming response real-time
- âœ… System Prompt - Äá»‹nh hÃ¬nh vai trÃ² gia sÆ° toÃ¡n há»c
- âœ… Error Handling - Xá»­ lÃ½ lá»—i toÃ n diá»‡n

### 2. **Frontend** (React + Vite)
- âœ… Chat Interface - Giao diá»‡n chat trá»±c quan
- âœ… Math Renderer - Hiá»ƒn thá»‹ cÃ´ng thá»©c LaTeX vá»›i KaTeX
- âœ… Queue Status - Hiá»ƒn thá»‹ tráº¡ng thÃ¡i hÃ ng Ä‘á»£i
- âœ… Streaming UI - Hiá»ƒn thá»‹ response tá»«ng pháº§n

### 3. **Triá»ƒn khai Local**
- âœ… Backend Ä‘ang cháº¡y táº¡i: `http://localhost:3000`
- âœ… Frontend Ä‘ang cháº¡y táº¡i: `http://localhost:5173`
- âœ… Model Deepseek-R1:8b Ä‘Ã£ sáºµn sÃ ng

---

## ğŸš€ HÆ°á»›ng dáº«n Sá»­ dá»¥ng

### Cháº¡y á»©ng dá»¥ng:

**Terminal 1 - Backend:**
```bash
cd /Users/mac/AIThink/backend
npm start
```

**Terminal 2 - Frontend:**
```bash
cd /Users/mac/AIThink/frontend
npm run dev
```

**Truy cáº­p:** Má»Ÿ trÃ¬nh duyá»‡t táº¡i `http://localhost:5173`

---

## ğŸ“ CÃ¡ch Sá»­ dá»¥ng

1. **Nháº­p cÃ¢u há»i toÃ¡n há»c** vÃ o Ã´ chat
2. **Há»— trá»£ LaTeX**: Sá»­ dá»¥ng `$x^2 + y^2$` cho inline math, `$$...$$` cho display math
3. **Enter** Ä‘á»ƒ gá»­i (Shift+Enter Ä‘á»ƒ xuá»‘ng dÃ²ng)
4. **Xem queue status** á»Ÿ thanh phÃ­a trÃªn Ä‘á»ƒ biáº¿t tráº¡ng thÃ¡i xá»­ lÃ½

### VÃ­ dá»¥ cÃ¢u há»i:

```
Giáº£i phÆ°Æ¡ng trÃ¬nh: $x^2 - 5x + 6 = 0$
```

```
TÃ­nh Ä‘áº¡o hÃ m cá»§a $f(x) = x^3 + 2x^2 - 5x + 1$
```

```
Chá»©ng minh Ä‘á»‹nh lÃ½ Pythagoras: $a^2 + b^2 = c^2$
```

---

## ğŸ”§ Cáº¥u hÃ¬nh

### Backend (.env):
```
OLLAMA_API_URL=http://127.0.0.1:11434
OLLAMA_MODEL=deepseek-r1:8b
PORT=3000
MAX_CONCURRENT_REQUESTS=3
```

### TÃ¹y chá»‰nh System Prompt:
Chá»‰nh sá»­a file: `backend/src/services/promptTemplates/system_tutor_role.txt`

---

## ğŸ¯ CÃ¡c BÆ°á»›c Tiáº¿p Theo

### Phase 2: Tá»‘i Æ°u hÃ³a (Äá» xuáº¥t)

1. **ThÃªm Authentication:**
   ```bash
   npm install jsonwebtoken bcrypt
   ```
   - Implement JWT authentication
   - Táº¡o user database (SQLite/MongoDB)

2. **Rate Limiting:**
   ```bash
   npm install express-rate-limit
   ```
   - Giá»›i háº¡n request/IP/hour

3. **Logging & Monitoring:**
   ```bash
   npm install winston morgan
   ```
   - Log requests vÃ  errors
   - Monitor system resources

4. **Input Validation:**
   ```bash
   npm install joi
   ```
   - Validate vÃ  sanitize user input
   - Prevent prompt injection

### Phase 3: Production Deployment

1. **Cloudflare Tunnel:**
   ```bash
   brew install cloudflare/cloudflare/cloudflared
   cloudflared login
   cloudflared tunnel create aithink
   ```

2. **Environment Variables:**
   - Táº¡o `.env.production`
   - Cáº¥u hÃ¬nh CORS cho production domain

3. **Process Manager:**
   ```bash
   npm install -g pm2
   pm2 start backend/src/server.js --name aithink-backend
   pm2 startup
   pm2 save
   ```

---

## ğŸ› Troubleshooting

### Lá»—i "Cannot connect to Ollama":
```bash
# Kiá»ƒm tra Ollama Ä‘ang cháº¡y
ollama list

# Khá»Ÿi Ä‘á»™ng Ollama náº¿u cáº§n
ollama serve
```

### Lá»—i "Port already in use":
```bash
# TÃ¬m vÃ  kill process Ä‘ang dÃ¹ng port
lsof -ti:3000 | xargs kill -9
lsof -ti:5173 | xargs kill -9
```

### Frontend khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Backend:
- Kiá»ƒm tra Backend Ä‘ang cháº¡y táº¡i port 3000
- Kiá»ƒm tra WebSocket connection trong Console cá»§a browser

---

## ğŸ“Š GiÃ¡m sÃ¡t Hiá»‡u suáº¥t

### Kiá»ƒm tra tÃ i nguyÃªn Mac mini:
```bash
# CPU vÃ  RAM usage
top

# Ollama processes
ps aux | grep ollama
```

### Test API:
```bash
# Health check
curl http://localhost:3000/api/health

# Queue status
curl http://localhost:3000/api/queue/status
```

---

## ğŸ¨ TÃ¹y chá»‰nh Giao diá»‡n

Chá»‰nh sá»­a: `frontend/src/styles/main.css`

CÃ¡c mÃ u chÃ­nh:
- Primary: `#667eea` (Purple)
- Secondary: `#764ba2` (Deep Purple)
- Background: Linear gradient

---

## ğŸ“š TÃ i liá»‡u Tham kháº£o

- **Ollama API**: https://github.com/ollama/ollama/blob/main/docs/api.md
- **Deepseek-R1**: https://ollama.com/library/deepseek-r1
- **KaTeX**: https://katex.org/docs/supported.html
- **Socket.IO**: https://socket.io/docs/v4/

---

## âœ¨ ÄÃ¡nh giÃ¡ Dá»± Ã¡n

### Æ¯u Ä‘iá»ƒm:
âœ… Kháº£ thi cao vá»›i Mac mini M2
âœ… Kiáº¿n trÃºc tá»‘t (queue, streaming, WebSocket)
âœ… UI Ä‘áº¹p vÃ  responsive
âœ… Há»— trá»£ LaTeX tá»‘t
âœ… Code clean vÃ  maintainable

### Háº¡n cháº¿ hiá»‡n táº¡i:
âš ï¸ ChÆ°a cÃ³ authentication
âš ï¸ ChÆ°a cÃ³ rate limiting
âš ï¸ ChÆ°a cÃ³ input validation
âš ï¸ ChÆ°a cÃ³ logging system
âš ï¸ ChÆ°a cÃ³ database (chat history)

### Thá»i gian pháº£n há»“i:
- CÃ¢u há»i Ä‘Æ¡n giáº£n: 5-15 giÃ¢y
- CÃ¢u há»i phá»©c táº¡p: 20-45 giÃ¢y
- Phá»¥ thuá»™c vÃ o Ä‘á»™ dÃ i vÃ  Ä‘á»™ phá»©c táº¡p cá»§a cÃ¢u há»i

---

## ğŸŠ Káº¿t luáº­n

Dá»± Ã¡n **AIThink** Ä‘Ã£ Ä‘Æ°á»£c triá»ƒn khai thÃ nh cÃ´ng á»Ÿ má»©c **MVP (Minimum Viable Product)**!

Báº¡n cÃ³ thá»ƒ:
1. âœ… Sá»­ dá»¥ng ngay trÃªn local (http://localhost:5173)
2. âœ… Test vá»›i cÃ¡c cÃ¢u há»i toÃ¡n há»c
3. âœ… Xem streaming response real-time
4. âœ… Theo dÃµi queue status

**Khuyáº¿n nghá»‹:** TrÆ°á»›c khi deploy production, hÃ£y implement cÃ¡c tÃ­nh nÄƒng báº£o máº­t (Phase 2) vÃ  setup Cloudflare Tunnel (Phase 3).

---

**Made with â¤ï¸ using Deepseek-R1 & Ollama**
