import axios from 'axios';
import fs from 'fs/promises';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

class OllamaService {
  constructor() {
    this.apiUrl = process.env.OLLAMA_API_URL || 'http://127.0.0.1:11434';
    this.model = process.env.OLLAMA_MODEL || 'deepseek-r1:8b';
    this.commonPrompt = null;
    this.tikzPrompt = null;
  }

  async initialize() {
    try {
      const commonPath = join(__dirname, 'promptTemplates', 'common-prompt.txt');
      const tikzPath = join(__dirname, 'promptTemplates', 'tikz-prompt.txt');
      
      this.commonPrompt = await fs.readFile(commonPath, 'utf-8');
      this.tikzPrompt = await fs.readFile(tikzPath, 'utf-8');
      
      console.log('‚úÖ System prompts loaded successfully');
    } catch (error) {
      console.error('‚ùå Failed to load system prompts:', error.message);
      this.commonPrompt = 'B·∫°n l√† m·ªôt tr·ª£ l√Ω to√°n h·ªçc chuy√™n nghi·ªáp.';
      this.tikzPrompt = '';
    }
  }

  // Detect if user message needs TikZ (geometry, graphs, tables)
  needsTikz(message) {
    const tikzKeywords = [
      'h√¨nh', 'v·∫Ω', 'ƒë·ªì th·ªã', 'bi·ªÉu ƒë·ªì', 'ƒë∆∞·ªùng', 'g√≥c', 'tam gi√°c', 't·ª© gi√°c', 
      'ƒë∆∞·ªùng tr√≤n', 'elip', 'parabol', 'hyperbol', 'ƒëa gi√°c', 'tr·ª•c t·ªça ƒë·ªô',
      'b·∫£ng bi·∫øn thi√™n', 'b·∫£ng x√©t d·∫•u', 'minh h·ªça', 'm√¥ t·∫£ h√¨nh',
      'geometry', 'graph', 'plot', 'draw', 'diagram', 'table', 'chart'
    ];
    
    const lowerMessage = message.toLowerCase();
    return tikzKeywords.some(keyword => lowerMessage.includes(keyword));
  }

  async chat(userMessage, onStream, abortSignal, selectedModel = null, apiKey = null) {
    const modelToUse = selectedModel || this.model;
    
    // Cloud models are called through local Ollama (after ollama pull)
    // No need for separate API endpoint or authentication
    if (modelToUse.includes(':cloud')) {
      console.log('‚òÅÔ∏è Using cloud model via local Ollama');
    }
    
    // Build system prompt: common + tikz (if needed)
    const useTikz = this.needsTikz(userMessage);
    const systemPrompt = useTikz 
      ? `${this.commonPrompt}\n\n${this.tikzPrompt}`
      : this.commonPrompt;
    
    if (useTikz) {
      console.log('üé® TikZ prompt added for visualization');
    }
    
    try {
      const response = await axios.post(
        `${this.apiUrl}/api/chat`,
        {
          model: modelToUse,
          messages: [
            {
              role: 'system',
              content: systemPrompt
            },
            {
              role: 'user',
              content: userMessage
            }
          ],
          stream: true
        },
        {
          responseType: 'stream',
          signal: abortSignal
        }
      );

      return new Promise((resolve, reject) => {
        let fullResponse = '';
        let stopped = false;

        // Handle abort signal
        if (abortSignal) {
          abortSignal.addEventListener('abort', () => {
            stopped = true;
            response.data.destroy();
            reject(new Error('Request aborted by user'));
          });
        }

        response.data.on('data', (chunk) => {
          if (stopped) return;

          const lines = chunk.toString().split('\n').filter(line => line.trim());
          
          for (const line of lines) {
            if (stopped) break;

            try {
              const json = JSON.parse(line);
              
              // Handle thinking tokens (Chain of Thought)
              if (json.message?.thinking) {
                fullResponse += json.message.thinking;
                if (onStream && !stopped) {
                  onStream(json.message.thinking, 'thinking');
                }
              }
              
              // Handle content tokens
              if (json.message?.content) {
                fullResponse += json.message.content;
                if (onStream && !stopped) {
                  onStream(json.message.content, 'content');
                }
              }
              
              if (json.done) {
                resolve(fullResponse);
              }
            } catch (e) {
              // Ignore parsing errors for incomplete chunks
            }
          }
        });

        response.data.on('error', (error) => {
          if (!stopped) {
            reject(error);
          }
        });

        response.data.on('end', () => {
          if (!stopped) {
            resolve(fullResponse);
          }
        });
      });
    } catch (error) {
      if (error.code === 'ERR_CANCELED' || error.message.includes('aborted')) {
        throw new Error('Request aborted by user');
      }
      console.error('‚ùå Ollama API error:', error.message);
      throw new Error('Failed to communicate with AI');
    }
  }

  async healthCheck() {
    try {
      const response = await axios.get(`${this.apiUrl}/api/tags`);
      return response.status === 200;
    } catch (error) {
      return false;
    }
  }
}

export default new OllamaService();
